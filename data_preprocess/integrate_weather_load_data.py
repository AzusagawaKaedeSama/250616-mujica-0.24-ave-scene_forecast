#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤©æ°”æ•°æ®ä¸è´Ÿè·æ•°æ®æ•´åˆè„šæœ¬
æ•´åˆæ¯ä¸ªåŸå¸‚2024å¹´çš„å¤©æ°”æ•°æ®å’Œè¯¥åŸå¸‚æ‰€åœ¨çœä»½çš„è´Ÿè·æ•°æ®
åœ¨dataæ–‡ä»¶å¤¹ä¸‹ç”ŸæˆåŒ…å«å¤©æ°”æ•°æ®çš„å„çœä»½çš„timeseries csvæ–‡ä»¶
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import glob
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# åŸå¸‚ä¸çœä»½æ˜ å°„å…³ç³»
CITY_PROVINCE_MAPPING = {
    'shanghai': 'ä¸Šæµ·',
    'nanjing': 'æ±Ÿè‹', 
    'hefei': 'å®‰å¾½',
    'hangzhou': 'æµ™æ±Ÿ',
    'fuzhou': 'ç¦å»º'
}

# åŸå¸‚ç›®å½•æ˜ å°„å…³ç³»ï¼ˆç”¨æˆ·æä¾›çš„å…·ä½“æ–‡ä»¶å¤¹åç§°ï¼‰
CITY_DIR_MAPPING = {
    'shanghai': 'shanghai_lon121.47_lat31.23',
    'nanjing': 'nanjing_lon118.78_lat32.06', 
    'hefei': 'hefei_lon117.27_lat31.86',
    'hangzhou': 'hangzhou_lon120.16_lat30.29',
    'fuzhou': 'fuzhou_lon119.30_lat26.08'
}

# å¤©æ°”æ•°æ®å­—æ®µæ˜ å°„
WEATHER_FIELD_MAPPING = {
    'u10': 'u_wind_10m',      # 10ç±³é«˜åº¦ué£åˆ†é‡ (m/s)
    'v10': 'v_wind_10m',      # 10ç±³é«˜åº¦vé£åˆ†é‡ (m/s)
    'd2m': 'dewpoint_2m',     # 2ç±³é«˜åº¦éœ²ç‚¹æ¸©åº¦ (K)
    't2m': 'temperature_2m',  # 2ç±³é«˜åº¦æ¸©åº¦ (K)
    'tp': 'total_precipitation' # æ€»é™æ°´é‡ (m)
}

def kelvin_to_celsius(temp_k):
    """å°†å¼€å°”æ–‡æ¸©åº¦è½¬æ¢ä¸ºæ‘„æ°åº¦"""
    return temp_k - 273.15

def calculate_wind_speed(u_wind, v_wind):
    """è®¡ç®—é£é€Ÿ"""
    return np.sqrt(u_wind**2 + v_wind**2)

def calculate_relative_humidity(temp_k, dewpoint_k):
    """æ ¹æ®æ¸©åº¦å’Œéœ²ç‚¹æ¸©åº¦è®¡ç®—ç›¸å¯¹æ¹¿åº¦"""
    # ä½¿ç”¨Magnuså…¬å¼è®¡ç®—ç›¸å¯¹æ¹¿åº¦
    temp_c = kelvin_to_celsius(temp_k)
    dewpoint_c = kelvin_to_celsius(dewpoint_k)
    
    # Magnuså…¬å¼å‚æ•°
    a = 17.27
    b = 237.7
    
    # è®¡ç®—é¥±å’Œæ°´æ±½å‹
    es_temp = 6.112 * np.exp((a * temp_c) / (b + temp_c))
    es_dewpoint = 6.112 * np.exp((a * dewpoint_c) / (b + dewpoint_c))
    
    # ç›¸å¯¹æ¹¿åº¦ = å®é™…æ°´æ±½å‹ / é¥±å’Œæ°´æ±½å‹ * 100
    rh = (es_dewpoint / es_temp) * 100
    return np.clip(rh, 0, 100)  # é™åˆ¶åœ¨0-100%ä¹‹é—´

def calculate_hdd_cdd(temp_c, base_temp=18):
    """è®¡ç®—ä¾›æš–åº¦æ—¥(HDD)å’Œåˆ¶å†·åº¦æ—¥(CDD)"""
    hdd = np.maximum(base_temp - temp_c, 0)
    cdd = np.maximum(temp_c - base_temp, 0)
    return hdd, cdd

def calculate_temp_change_rate(temp_series):
    """è®¡ç®—æ¸©åº¦å˜åŒ–ç‡"""
    temp_change = temp_series.diff()
    return temp_change.fillna(0)

def load_weather_data_for_city(city_dir):
    """åŠ è½½æŸä¸ªåŸå¸‚çš„å…¨å¹´å¤©æ°”æ•°æ®"""
    logger.info(f"æ­£åœ¨åŠ è½½åŸå¸‚å¤©æ°”æ•°æ®: {city_dir}")
    
    weather_data_list = []
    
    # éå†æ‰€æœ‰æœˆä»½ç›®å½•
    for month in range(1, 13):
        month_dir = os.path.join(city_dir, f"2024-{month:02d}")
        if not os.path.exists(month_dir):
            logger.warning(f"æœˆä»½ç›®å½•ä¸å­˜åœ¨: {month_dir}")
            continue
            
        # æŸ¥æ‰¾CSVæ–‡ä»¶
        csv_files = glob.glob(os.path.join(month_dir, "*.csv"))
        if not csv_files:
            logger.warning(f"åœ¨ç›®å½• {month_dir} ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
            continue
            
        csv_file = csv_files[0]  # å–ç¬¬ä¸€ä¸ªCSVæ–‡ä»¶
        logger.info(f"åŠ è½½æ–‡ä»¶: {csv_file}")
        
        try:
            df = pd.read_csv(csv_file)
            weather_data_list.append(df)
        except Exception as e:
            logger.error(f"åŠ è½½æ–‡ä»¶å¤±è´¥ {csv_file}: {e}")
            continue
    
    if not weather_data_list:
        logger.error(f"æœªèƒ½åŠ è½½ä»»ä½•å¤©æ°”æ•°æ®: {city_dir}")
        return None
    
    # åˆå¹¶æ‰€æœ‰æœˆä»½æ•°æ®
    weather_df = pd.concat(weather_data_list, ignore_index=True)
    
    # è½¬æ¢æ—¶é—´æ ¼å¼
    weather_df['datetime'] = pd.to_datetime(weather_df['valid_time'])
    weather_df = weather_df.sort_values('datetime').reset_index(drop=True)
    
    logger.info(f"æˆåŠŸåŠ è½½å¤©æ°”æ•°æ®ï¼Œå…± {len(weather_df)} æ¡è®°å½•")
    return weather_df

def process_weather_data(weather_df):
    """å¤„ç†å¤©æ°”æ•°æ®ï¼Œè®¡ç®—è¡ç”ŸæŒ‡æ ‡"""
    logger.info("æ­£åœ¨å¤„ç†å¤©æ°”æ•°æ®...")
    
    # åŸºç¡€è½¬æ¢
    weather_df['weather_temperature_c'] = kelvin_to_celsius(weather_df['t2m'])
    weather_df['weather_dewpoint_c'] = kelvin_to_celsius(weather_df['d2m'])
    weather_df['weather_wind_speed'] = calculate_wind_speed(weather_df['u10'], weather_df['v10'])
    
    # è®¡ç®—ç›¸å¯¹æ¹¿åº¦
    weather_df['weather_relative_humidity'] = calculate_relative_humidity(
        weather_df['t2m'], weather_df['d2m']
    )
    
    # è®¡ç®—HDDå’ŒCDD
    hdd, cdd = calculate_hdd_cdd(weather_df['weather_temperature_c'])
    weather_df['weather_HDD'] = hdd
    weather_df['weather_CDD'] = cdd
    
    # è®¡ç®—æ¸©åº¦å˜åŒ–ç‡
    weather_df['weather_temp_change_rate'] = calculate_temp_change_rate(
        weather_df['weather_temperature_c']
    )
    
    # é™æ°´é‡è½¬æ¢ (m -> mm)
    weather_df['weather_precipitation_mm'] = weather_df['tp'] * 1000
    
    # é€‰æ‹©éœ€è¦çš„åˆ—
    processed_columns = [
        'datetime', 'weather_temperature_c', 'weather_wind_speed', 
        'weather_relative_humidity', 'weather_HDD', 'weather_CDD', 
        'weather_temp_change_rate', 'weather_precipitation_mm',
        'weather_dewpoint_c', 'u10', 'v10'
    ]
    
    return weather_df[processed_columns]

def interpolate_weather_to_15min(weather_df):
    """å°†å°æ—¶çº§å¤©æ°”æ•°æ®æ’å€¼åˆ°15åˆ†é’Ÿé—´éš”"""
    logger.info("æ­£åœ¨å°†å¤©æ°”æ•°æ®æ’å€¼åˆ°15åˆ†é’Ÿé—´éš”...")
    
    # ç¡®ä¿datetimeåˆ—æ˜¯datetimeç±»å‹
    weather_df['datetime'] = pd.to_datetime(weather_df['datetime'])
    
    # å»é™¤é‡å¤çš„æ—¶é—´æˆ³ï¼Œä¿ç•™ç¬¬ä¸€ä¸ª
    weather_df = weather_df.drop_duplicates(subset=['datetime'], keep='first')
    logger.info(f"å»é™¤é‡å¤æ—¶é—´æˆ³åï¼Œå‰©ä½™ {len(weather_df)} æ¡è®°å½•")
    
    # è®¾ç½®datetimeä¸ºç´¢å¼•
    weather_df = weather_df.set_index('datetime').sort_index()
    
    # åˆ›å»º15åˆ†é’Ÿé—´éš”çš„æ—¶é—´åºåˆ—
    start_time = weather_df.index.min()
    end_time = weather_df.index.max()
    freq_15min = pd.date_range(start=start_time, end=end_time, freq='15min')
    
    # å¯¹æ•°å€¼åˆ—è¿›è¡Œçº¿æ€§æ’å€¼
    numeric_cols = weather_df.select_dtypes(include=[np.number]).columns
    weather_15min = weather_df[numeric_cols].reindex(freq_15min).interpolate(method='linear')
    
    # é‡ç½®ç´¢å¼•ï¼Œå°†datetimeä½œä¸ºåˆ—
    weather_15min = weather_15min.reset_index()
    weather_15min.rename(columns={'index': 'datetime'}, inplace=True)
    
    logger.info(f"æ’å€¼å®Œæˆï¼Œå…± {len(weather_15min)} æ¡è®°å½•")
    return weather_15min

def load_load_data(province):
    """åŠ è½½çœä»½è´Ÿè·æ•°æ®"""
    load_file = f"../data/timeseries_load_{province}.csv"
    
    if not os.path.exists(load_file):
        logger.error(f"è´Ÿè·æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {load_file}")
        return None
    
    logger.info(f"æ­£åœ¨åŠ è½½è´Ÿè·æ•°æ®: {load_file}")
    
    try:
        load_df = pd.read_csv(load_file)
        load_df['datetime'] = pd.to_datetime(load_df['datetime'])
        load_df = load_df.sort_values('datetime').reset_index(drop=True)
        logger.info(f"æˆåŠŸåŠ è½½è´Ÿè·æ•°æ®ï¼Œå…± {len(load_df)} æ¡è®°å½•")
        return load_df
    except Exception as e:
        logger.error(f"åŠ è½½è´Ÿè·æ•°æ®å¤±è´¥: {e}")
        return None

def merge_weather_load_data(weather_df, load_df, province):
    """åˆå¹¶å¤©æ°”æ•°æ®å’Œè´Ÿè·æ•°æ®"""
    logger.info(f"æ­£åœ¨åˆå¹¶ {province} çš„å¤©æ°”æ•°æ®å’Œè´Ÿè·æ•°æ®...")
    
    # åŸºäºæ—¶é—´æˆ³åˆå¹¶æ•°æ®
    merged_df = pd.merge(load_df, weather_df, on='datetime', how='inner')
    
    logger.info(f"åˆå¹¶å®Œæˆï¼Œå…± {len(merged_df)} æ¡è®°å½•")
    
    # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
    missing_load = merged_df['load'].isna().sum()
    missing_weather = merged_df['weather_temperature_c'].isna().sum()
    
    if missing_load > 0:
        logger.warning(f"è´Ÿè·æ•°æ®ç¼ºå¤± {missing_load} æ¡")
    if missing_weather > 0:
        logger.warning(f"å¤©æ°”æ•°æ®ç¼ºå¤± {missing_weather} æ¡")
    
    return merged_df

def save_integrated_data(merged_df, province):
    """ä¿å­˜æ•´åˆåçš„æ•°æ®"""
    output_file = f"../data/timeseries_load_weather_{province}.csv"
    
    logger.info(f"æ­£åœ¨ä¿å­˜æ•´åˆæ•°æ®åˆ°: {output_file}")
    
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        # ä¿å­˜æ•°æ®
        merged_df.to_csv(output_file, index=False, encoding='utf-8')
        
        logger.info(f"æˆåŠŸä¿å­˜æ•´åˆæ•°æ®ï¼Œæ–‡ä»¶å¤§å°: {os.path.getsize(output_file) / 1024 / 1024:.2f} MB")
        
        # æ‰“å°æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        print(f"\n=== {province} æ•°æ®ç»Ÿè®¡ ===")
        print(f"æ—¶é—´èŒƒå›´: {merged_df['datetime'].min()} åˆ° {merged_df['datetime'].max()}")
        print(f"æ•°æ®æ¡æ•°: {len(merged_df)}")
        print(f"è´Ÿè·èŒƒå›´: {merged_df['load'].min():.1f} - {merged_df['load'].max():.1f}")
        print(f"æ¸©åº¦èŒƒå›´: {merged_df['weather_temperature_c'].min():.1f}Â°C - {merged_df['weather_temperature_c'].max():.1f}Â°C")
        print(f"é£é€ŸèŒƒå›´: {merged_df['weather_wind_speed'].min():.1f} - {merged_df['weather_wind_speed'].max():.1f} m/s")
        print(f"ç›¸å¯¹æ¹¿åº¦èŒƒå›´: {merged_df['weather_relative_humidity'].min():.1f}% - {merged_df['weather_relative_humidity'].max():.1f}%")
        
    except Exception as e:
        logger.error(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    return True

def process_city_data(city_name):
    """å¤„ç†å•ä¸ªåŸå¸‚çš„æ•°æ®"""
    logger.info(f"\n{'='*50}")
    logger.info(f"å¼€å§‹å¤„ç†åŸå¸‚: {city_name}")
    logger.info(f"{'='*50}")
    
    # è·å–çœä»½åç§°
    province = CITY_PROVINCE_MAPPING.get(city_name)
    if not province:
        logger.error(f"æœªæ‰¾åˆ°åŸå¸‚ {city_name} å¯¹åº”çš„çœä»½")
        return False
    
    # è·å–åŸå¸‚ç›®å½•åç§°
    city_dir = CITY_DIR_MAPPING.get(city_name)
    if not city_dir:
        logger.error(f"æœªæ‰¾åˆ°åŸå¸‚ {city_name} å¯¹åº”çš„ç›®å½•åç§°")
        return False
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(city_dir):
        logger.error(f"åŸå¸‚ç›®å½•ä¸å­˜åœ¨: {city_dir}")
        return False
    
    # 1. åŠ è½½å¤©æ°”æ•°æ®
    weather_df = load_weather_data_for_city(city_dir)
    if weather_df is None:
        return False
    
    # 2. å¤„ç†å¤©æ°”æ•°æ®
    weather_processed = process_weather_data(weather_df)
    
    # 3. æ’å€¼åˆ°15åˆ†é’Ÿé—´éš”
    weather_15min = interpolate_weather_to_15min(weather_processed)
    
    # 4. åŠ è½½è´Ÿè·æ•°æ®
    load_df = load_load_data(province)
    if load_df is None:
        return False
    
    # 5. åˆå¹¶æ•°æ®
    merged_df = merge_weather_load_data(weather_15min, load_df, province)
    
    # 6. ä¿å­˜æ•´åˆæ•°æ®
    success = save_integrated_data(merged_df, province)
    
    if success:
        logger.info(f"âœ… {city_name} ({province}) æ•°æ®å¤„ç†å®Œæˆ")
    else:
        logger.error(f"âŒ {city_name} ({province}) æ•°æ®å¤„ç†å¤±è´¥")
    
    return success

def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹å¤©æ°”æ•°æ®ä¸è´Ÿè·æ•°æ®æ•´åˆä»»åŠ¡")
    logger.info(f"å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # ç»Ÿè®¡ç»“æœ
    success_count = 0
    total_count = len(CITY_PROVINCE_MAPPING)
    
    # å¤„ç†æ¯ä¸ªåŸå¸‚
    for city_name in CITY_PROVINCE_MAPPING.keys():
        logger.info("\n" + "="*50)
        logger.info(f"å¼€å§‹å¤„ç†åŸå¸‚: {city_name}")
        logger.info("="*50)
        
        try:
            process_city_data(city_name)
            success_count += 1
        except Exception as e:
            logger.error(f"å¤„ç†åŸå¸‚ {city_name} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            continue
    
    logger.info("\n" + "="*60)
    logger.info("ä»»åŠ¡å®Œæˆï¼")
    logger.info(f"æˆåŠŸå¤„ç†: {success_count}/{total_count} ä¸ªåŸå¸‚")
    logger.info("="*60)
    
    if success_count == total_count:
        logger.info("ğŸ‰ æ‰€æœ‰åŸå¸‚æ•°æ®å¤„ç†æˆåŠŸï¼")
    else:
        logger.warning(f"âš ï¸  æœ‰ {total_count - success_count} ä¸ªåŸå¸‚å¤„ç†å¤±è´¥")

if __name__ == "__main__":
    main() 